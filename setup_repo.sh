#!/bin/bash
# Automated setup script for phenotype-detection-pipeline GitHub repository
# Run this after creating your GitHub repo and cloning it locally

set -e  # Exit on error

echo "ğŸš€ Setting up phenotype-detection-pipeline repository..."
echo ""

# Check if we're in a git repo
if [ ! -d ".git" ]; then
    echo "âŒ Error: Not in a git repository."
    echo "   Please run this script from your cloned repository directory."
    exit 1
fi

echo "âœ… Git repository detected"

# Create directory structure
echo "ğŸ“ Creating directory structure..."
mkdir -p src docs examples config tests

# Create __init__.py
echo "ğŸ“ Creating src/__init__.py..."
cat > src/__init__.py << 'EOF'
"""
Artifact-Free Phenotype Detection Pipeline

A production-ready deep learning pipeline for detecting biological 
phenotypes while avoiding technical artifacts through intelligent 
class design.
"""

__version__ = "1.0.0"
__author__ = "Your Name"
__email__ = "your.email@example.com"

from .prepare_dataset import *
from .train_models import *
from .evaluate_models import *
from .analyze_results import *
EOF

# Check if pipeline scripts exist and move them
echo "ğŸ”„ Organizing pipeline scripts..."

if [ -f "1_prepare_dataset.py" ]; then
    mv 1_prepare_dataset.py src/prepare_dataset.py
    echo "  âœ“ Moved prepare_dataset.py"
elif [ ! -f "src/prepare_dataset.py" ]; then
    echo "  âš ï¸  Warning: prepare_dataset.py not found"
fi

if [ -f "2_train_models.py" ]; then
    mv 2_train_models.py src/train_models.py
    echo "  âœ“ Moved train_models.py"
elif [ ! -f "src/train_models.py" ]; then
    echo "  âš ï¸  Warning: train_models.py not found"
fi

if [ -f "3_evaluate_models.py" ]; then
    mv 3_evaluate_models.py src/evaluate_models.py
    echo "  âœ“ Moved evaluate_models.py"
elif [ ! -f "src/evaluate_models.py" ]; then
    echo "  âš ï¸  Warning: evaluate_models.py not found"
fi

if [ -f "4_analyze_results.py" ]; then
    mv 4_analyze_results.py src/analyze_results.py
    echo "  âœ“ Moved analyze_results.py"
elif [ ! -f "src/analyze_results.py" ]; then
    echo "  âš ï¸  Warning: analyze_results.py not found"
fi

# Move documentation
echo "ğŸ“š Organizing documentation..."

if [ -f "QUICKSTART.md" ]; then
    mv QUICKSTART.md docs/
    echo "  âœ“ Moved QUICKSTART.md"
fi

if [ -f "METHODOLOGY.md" ]; then
    mv METHODOLOGY.md docs/
    echo "  âœ“ Moved METHODOLOGY.md"
fi

if [ -f "PACKAGE_MANIFEST.md" ]; then
    mv PACKAGE_MANIFEST.md docs/USAGE.md
    echo "  âœ“ Moved PACKAGE_MANIFEST.md â†’ USAGE.md"
fi

if [ -f "INDEX.md" ]; then
    mv INDEX.md docs/
    echo "  âœ“ Moved INDEX.md"
fi

# Move examples
echo "ğŸ“– Organizing examples..."

if [ -f "example_commands.sh" ]; then
    mv example_commands.sh examples/
    echo "  âœ“ Moved example_commands.sh"
fi

if [ -f "expected_outputs.md" ]; then
    mv expected_outputs.md examples/
    echo "  âœ“ Moved expected_outputs.md"
fi

# Create requirements.txt if it doesn't exist
if [ ! -f "requirements.txt" ]; then
    echo "ğŸ“¦ Creating requirements.txt..."
    cat > requirements.txt << 'EOF'
# Core dependencies
torch>=2.0.0
torchvision>=0.15.0
pytorch-lightning>=2.0.0

# Data handling
pandas>=1.5.0
numpy>=1.24.0
h5py>=3.8.0
Pillow>=9.5.0

# Visualization
matplotlib>=3.7.0
seaborn>=0.12.0

# Machine learning utilities
scikit-learn>=1.2.0
tqdm>=4.65.0

# Optional but recommended
tensorboard>=2.13.0
EOF
    echo "  âœ“ Created requirements.txt"
else
    echo "  â„¹ï¸  requirements.txt already exists"
fi

# Create/update .gitignore
if [ ! -f ".gitignore" ]; then
    echo "ğŸš« Creating .gitignore..."
    cat > .gitignore << 'EOF'
# Python
__pycache__/
*.py[cod]
*.so
.Python
venv/
ENV/
*.egg-info/

# PyTorch
*.pth
*.ckpt

# Data - IMPORTANT: Don't commit large files
data/
dataset/
datasets/
*.h5
*.hdf5
raw_data/
processed_data/

# Results
results/
outputs/
models/
checkpoints/
logs/
evaluation/
analysis/
figures/

# Images and arrays (except documentation)
*.png
!docs/**/*.png
*.jpg
*.jpeg
*.npy
*.npz

# TensorBoard
runs/
lightning_logs/

# OS
.DS_Store
Thumbs.db

# IDEs
.vscode/
.idea/
*.swp

# Environment
.env
*.log
EOF
    echo "  âœ“ Created .gitignore"
else
    echo "  â„¹ï¸  .gitignore already exists"
fi

# Create example config
echo "âš™ï¸  Creating example config..."
cat > config/default_config.yaml << 'EOF'
# Default configuration for phenotype detection pipeline

# Data paths
data:
  hdf5_dir: "/path/to/hdf5_neurons"
  output_dir: "./dataset"
  bad_wells: ["A1", "A2", "A3"]

# Training parameters
training:
  batch_size: 32
  epochs: 100
  learning_rate: 0.001
  num_workers: 4
  architecture: "resnet18"

# Channels to train
channels:
  - "RFP1"
  - "Halo"

# Tasks
tasks:
  - "6class"

# Evaluation
evaluation:
  channels:
    - "RFP1"
    - "Halo"
EOF
echo "  âœ“ Created default_config.yaml"

# Create simple test file
echo "ğŸ§ª Creating test template..."
cat > tests/test_prepare_dataset.py << 'EOF'
"""
Unit tests for prepare_dataset.py

Run with: pytest tests/
"""

import pytest
import pandas as pd
from pathlib import Path

def test_imports():
    """Test that all imports work"""
    try:
        import sys
        sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))
        from prepare_dataset import extract_condition_info
        assert True
    except ImportError:
        pytest.fail("Failed to import prepare_dataset")

def test_metadata_structure():
    """Test metadata DataFrame structure"""
    # Add your tests here
    pass

# Add more tests as needed
EOF
echo "  âœ“ Created test template"

# Create simple setup.py for installation
echo "ğŸ“¦ Creating setup.py..."
cat > setup.py << 'EOF'
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

setup(
    name="phenotype-detection-pipeline",
    version="1.0.0",
    author="Your Name",
    author_email="your.email@example.com",
    description="Artifact-free phenotype detection using deep learning",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/yourusername/phenotype-detection-pipeline",
    packages=find_packages(),
    classifiers=[
        "Programming Language :: Python :: 3",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
    ],
    python_requires='>=3.8',
    install_requires=[
        "torch>=2.0.0",
        "torchvision>=0.15.0",
        "pytorch-lightning>=2.0.0",
        "pandas>=1.5.0",
        "numpy>=1.24.0",
        "h5py>=3.8.0",
        "Pillow>=9.5.0",
        "matplotlib>=3.7.0",
        "seaborn>=0.12.0",
        "scikit-learn>=1.2.0",
        "tqdm>=4.65.0",
    ],
)
EOF
echo "  âœ“ Created setup.py"

# Stage all changes
echo ""
echo "ğŸ“‹ Staging changes..."
git add .

# Show status
echo ""
echo "ğŸ“Š Repository status:"
git status

echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo "âœ… Setup complete!"
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
echo ""
echo "ğŸ“ Directory structure created:"
echo "   src/       - Source code"
echo "   docs/      - Documentation"
echo "   examples/  - Usage examples"
echo "   config/    - Configuration files"
echo "   tests/     - Unit tests"
echo ""
echo "ğŸ“ Next steps:"
echo "   1. Review the staged changes: git status"
echo "   2. Update README.md with your info"
echo "   3. Update setup.py with your details"
echo "   4. Commit changes: git commit -m 'Initial repository setup'"
echo "   5. Push to GitHub: git push origin main"
echo "   6. Start using with Claude Code!"
echo ""
echo "ğŸ¤– To use with Claude Code:"
echo "   $ claude-code"
echo "   Then: 'Help me customize this pipeline for my experiment'"
echo ""
echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
